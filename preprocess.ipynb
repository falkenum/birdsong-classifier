{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import noisereduce as nr  \n",
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filedirpath = Path(\"./wav/\").resolve()\n",
    "outdirpath = Path(\"./stage1/\").resolve()\n",
    "\n",
    "filenames = sorted(os.listdir(filedirpath))\n",
    "\n",
    "for filename in filenames:\n",
    "    filepath = filedirpath.joinpath(filename)\n",
    "\n",
    "    data, fs = torchaudio.load(str(filepath))\n",
    "    data_np = np.mean(data.numpy(), axis=0)\n",
    "    data_np = data_np / np.max(data_np)\n",
    "    resampled = torchaudio.functional.resample(torch.from_numpy(data_np)[None, :], fs, 32000)\n",
    "    torchaudio.save(outdirpath.joinpath(filename), resampled, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = Path('./resampled/')\n",
    "outdir = Path('./chunks/')\n",
    "\n",
    "SR = 32000\n",
    "SECONDS_PER_SAMPLE = 30\n",
    "\n",
    "# for classname in classnames:\n",
    "# classdir = indir.joinpath(classname)\n",
    "\n",
    "classdata = torch.tensor([], dtype=torch.float32)\n",
    "filenames = sorted(os.listdir(indir))\n",
    "\n",
    "current_class = None\n",
    "outi = 0\n",
    "for filename in filenames:\n",
    "    classname = filename[:filename.index('-', filename.index('-') + 1)]\n",
    "    \n",
    "    if current_class != classname:\n",
    "        if current_class is not None:\n",
    "            chunks = torch.split(classdata, split_size_or_sections=SR*SECONDS_PER_SAMPLE, dim=1)[:-1]\n",
    "            for chunk in chunks:\n",
    "                outpath = outdir.joinpath(f'{current_class}_{outi}.wav')\n",
    "                torchaudio.save(str(outpath), chunk, SR)\n",
    "                outi += 1\n",
    "\n",
    "        outi = 0\n",
    "        current_class = classname\n",
    "    \n",
    "    data, sr = torchaudio.load(str(indir.joinpath(filename)))\n",
    "    assert(sr == SR)\n",
    "    assert(data.dtype == torch.float32)\n",
    "    chunks = torch.split(data, split_size_or_sections=SR*SECONDS_PER_SAMPLE, dim=1)\n",
    "\n",
    "    for chunk in chunks[:-1]:\n",
    "        outpath = outdir.joinpath(f'{current_class}_{outi}.wav')\n",
    "        torchaudio.save(str(outpath), chunk, SR)\n",
    "        outi += 1\n",
    "    \n",
    "    classdata = torch.cat((classdata, chunks[-1]), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_length = n_fft // 4\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "data = None # TODO\n",
    "\n",
    "def myspecshow(data, ax):\n",
    "    spec = np.abs(lr.stft(data, n_fft=n_fft, hop_length=hop_length))**2\n",
    "    mspec = lr.feature.melspectrogram(sr=fs, S=spec)\n",
    "\n",
    "    mspec = lr.power_to_db(mspec, ref=np.max)\n",
    "    return mspec, specshow(mspec, sr=fs, y_axis='mel', x_axis='time', hop_length=hop_length, ax=ax)\n",
    "\n",
    "data_np = np.mean(data.numpy(), axis=0)\n",
    "print(data_np.shape)\n",
    "data_np = data_np / np.max(data_np)\n",
    "data_filt = nr.reduce_noise(data_np, fs)\n",
    "torchaudio.save('filtered.wav', torch.from_numpy(data_filt[None, :]), fs)\n",
    "\n",
    "spec, img = myspecshow(data_filt, ax[0])\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "\n",
    "o_env = lr.onset.onset_strength(sr=fs, S=spec)\n",
    "times = lr.times_like(o_env, sr=fs)\n",
    "onsets = lr.onset.onset_detect(onset_envelope=o_env, sr=fs)\n",
    "print(onsets[:10])\n",
    "\n",
    "\n",
    "ax[1].vlines(times[onsets], 0, o_env.max(), color='r', alpha=0.9)\n",
    "ax[1].plot(times, o_env)\n",
    "ax[1].set_xlim(times[0], times[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a770cf58d2f81b78170aa77ee89804a8202ff8c1a5c88ca057536bfcf230f8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
